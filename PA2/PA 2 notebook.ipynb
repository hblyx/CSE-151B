{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import data\n",
    "import neuralnet\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(seed = 100) # fix random seed to make things reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (a) Loading Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "((60000, 784), (60000,))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = data.load_data()\n",
    "train_val[0].shape, train_val[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((10000, 784), (10000,))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.load_data(train=False)\n",
    "test[0].shape, test[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-process\n",
    "#### Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_x, train_y = train_val\n",
    "train_x, _ = data.z_score_normalize(train_x)\n",
    "train_val = train_x, train_y\n",
    "\n",
    "test_x, test_y = test\n",
    "test_x, _ = data.z_score_normalize(test_x)\n",
    "test_val = test_x, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (b) Check gradient implementation\n",
    "\n",
    "We only use a small subset of data to do this part. Thus, we use 1000 random data from the train/validation set.\n",
    "\n",
    "##### get a small subset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# shuffle dataset\n",
    "imgs, labs = train_val\n",
    "\n",
    "shuffled_idx = np.random.permutation(len(train_val[1]))\n",
    "\n",
    "imgs = imgs[shuffled_idx]\n",
    "labs =labs[shuffled_idx]\n",
    "\n",
    "# get a small subset\n",
    "small_set = imgs[: 1], labs[:1]\n",
    "print(small_set[0].shape)\n",
    "print(small_set[1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### get some functions to find weight and gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get a network first\n",
    "config = data.load_config((\"./config.yaml\"))\n",
    "nn = neuralnet.NeuralNetwork(config)\n",
    "\n",
    "small_x, small_y = small_set[0], small_set[1]\n",
    "\n",
    "# get a nn\n",
    "output = nn(small_x, targets=small_y)\n",
    "\n",
    "# get weights by backpropagation\n",
    "nn.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "epsilon = 0.01\n",
    "\n",
    "def get_weight_grad(name, layer, idx, nn, is_bias=False):\n",
    "    if is_bias:\n",
    "        weight = nn.layers[layer].b[0][idx]\n",
    "        grad = nn.layers[layer].d_b[idx]\n",
    "    else:\n",
    "        weight = nn.layers[layer].w[0][idx]\n",
    "        grad = nn.layers[layer].d_w[0][idx]\n",
    "\n",
    "    print(name, \":(\", \"weight:\", weight, \"gradient:\", grad, \")\")\n",
    "    return weight, grad\n",
    "\n",
    "def get_loss(weight, layer, idx, nn, is_bias=False):\n",
    "    higher = weight + epsilon\n",
    "    lower = weight - epsilon\n",
    "\n",
    "    if is_bias:\n",
    "        nn.layers[layer].b[0][idx] = higher\n",
    "        _, higher_loss = nn.forward(small_x, targets=small_y)\n",
    "        nn.layers[layer].b[0][idx] = lower\n",
    "        _, lower_loss = nn.forward(small_x, targets=small_y)\n",
    "\n",
    "        # reset nn\n",
    "        nn.layers[layer].b[0][idx] = weight\n",
    "    else:\n",
    "        nn.layers[layer].w[0][idx] = higher\n",
    "        _, higher_loss = nn.forward(small_x, targets=small_y)\n",
    "        nn.layers[layer].w[0][idx] = lower\n",
    "        _, lower_loss = nn.forward(small_x, targets=small_y)\n",
    "\n",
    "        # reset nn\n",
    "        nn.layers[layer].w[0][idx] = weight\n",
    "\n",
    "    print(\"Higher loss is:\", higher_loss)\n",
    "    print(\"Lower loss is:\", lower_loss)\n",
    "    return higher_loss, lower_loss\n",
    "\n",
    "def get_estimate(higher, lower):\n",
    "    est = (higher - lower) / (2 * epsilon)\n",
    "    print(\"estimated gradient is:\", est)\n",
    "    return est\n",
    "\n",
    "def diff_grad(grad, est):\n",
    "    diff = np.abs((grad - est))\n",
    "    print(\"difference between estimated and gradient is:\", diff)\n",
    "    return diff\n",
    "\n",
    "def check_grad(name, layer, idx, nn, is_bias=False):\n",
    "    weight, grad = get_weight_grad(name, layer, idx, nn, is_bias=is_bias)\n",
    "    higher, lower = get_loss(weight, layer, idx, nn, is_bias=is_bias)\n",
    "    est = get_estimate(higher, lower)\n",
    "    diff = diff_grad(grad, est)\n",
    "\n",
    "    return diff, grad, est"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### bias of output weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output bias :( weight: 0.0 gradient: 0.012671104872593866 )\n",
      "Higher loss is: 2.153077486743764\n",
      "Lower loss is: 2.152824060581794\n",
      "estimated gradient is: 0.0126713080984997\n",
      "difference between estimated and gradient is: 2.0322590583467248e-07\n"
     ]
    }
   ],
   "source": [
    "# bias of output\n",
    "b_o_diff, b_o_grad, b_o_est = check_grad(\"output bias\", 2, 7, nn, is_bias=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### bias of hidden weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden bias :( weight: 0.0 gradient: -0.1182257632568207 )\n",
      "Higher loss is: 2.1517643388554943\n",
      "Lower loss is: 2.1541287967614338\n",
      "estimated gradient is: -0.11822289529697105\n",
      "difference between estimated and gradient is: 2.8679598496478276e-06\n"
     ]
    }
   ],
   "source": [
    "b_h_diff, b_h_grad, b_h_est = check_grad(\"hidden bias\", 0, 7, nn, is_bias=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### weight of hidden to output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden-output weight_1 :( weight: 0.0959293411441136 gradient: 0.009273564165974427 )\n",
      "Higher loss is: 2.153043219621119\n",
      "Lower loss is: 2.152857746744473\n",
      "estimated gradient is: 0.009273643832297118\n",
      "difference between estimated and gradient is: 7.966632269151841e-08\n",
      "hidden-output weight_2 :( weight: -0.058684298241869014 gradient: 0.009660359079762365 )\n",
      "Higher loss is: 2.153047101390139\n",
      "Lower loss is: 2.152853892551448\n",
      "estimated gradient is: 0.009660441934533637\n",
      "difference between estimated and gradient is: 8.285477127133178e-08\n"
     ]
    }
   ],
   "source": [
    "w_ho_1_diff, w_ho_1_grad, w_ho_1_est = check_grad(\"hidden-output weight_1\", 2, 7, nn, is_bias=False)\n",
    "w_ho_2_diff, w_ho_2_grad, w_ho_2_est = check_grad(\"hidden-output weight_2\", 2, 8, nn, is_bias=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### weight of input to hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input-hidden weight_1 :( weight: 0.03876130722157737 gradient: 0.005871529380401278 )\n",
      "Higher loss is: 2.153008854589536\n",
      "Lower loss is: 2.152891424008954\n",
      "estimated gradient is: 0.00587152902908894\n",
      "difference between estimated and gradient is: 3.513123377277272e-10\n",
      "input-hidden weight_2 :( weight: -0.023712037277713923 gradient: -0.005488742979949136 )\n",
      "Higher loss is: 2.1528952505826426\n",
      "Lower loss is: 2.153005025436887\n",
      "estimated gradient is: -0.005488742712222994\n",
      "difference between estimated and gradient is: 2.677261424707811e-10\n"
     ]
    }
   ],
   "source": [
    "w_ih_1_diff, w_ih_1_grad, w_ih_1_est = check_grad(\"input-hidden weight_1\", 0, 7, nn, is_bias=False)\n",
    "w_ih_2_diff, w_ih_2_grad, w_ih_2_est = check_grad(\"input-hidden weight_2\", 0, 8, nn, is_bias=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Report Table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "           name of weight              difference        actual gradient  \\\n0             output bias  2.0322590583467248e-07   0.012671104872593866   \n1             hidden bias  2.8679598496478276e-06    -0.1182257632568207   \n2  hidden-output weight_1   7.966632269151841e-08   0.009273564165974427   \n3  hidden-output weight_2   8.285477127133178e-08   0.009660359079762365   \n4   input-hidden weight_1   3.513123377277272e-10   0.005871529380401278   \n5   input-hidden weight_2   2.677261424707811e-10  -0.005488742979949136   \n\n      estimated gradient  \n0     0.0126713080984997  \n1   -0.11822289529697105  \n2   0.009273643832297118  \n3   0.009660441934533637  \n4    0.00587152902908894  \n5  -0.005488742712222994  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name of weight</th>\n      <th>difference</th>\n      <th>actual gradient</th>\n      <th>estimated gradient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>output bias</td>\n      <td>2.0322590583467248e-07</td>\n      <td>0.012671104872593866</td>\n      <td>0.0126713080984997</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hidden bias</td>\n      <td>2.8679598496478276e-06</td>\n      <td>-0.1182257632568207</td>\n      <td>-0.11822289529697105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hidden-output weight_1</td>\n      <td>7.966632269151841e-08</td>\n      <td>0.009273564165974427</td>\n      <td>0.009273643832297118</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hidden-output weight_2</td>\n      <td>8.285477127133178e-08</td>\n      <td>0.009660359079762365</td>\n      <td>0.009660441934533637</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>input-hidden weight_1</td>\n      <td>3.513123377277272e-10</td>\n      <td>0.005871529380401278</td>\n      <td>0.00587152902908894</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>input-hidden weight_2</td>\n      <td>2.677261424707811e-10</td>\n      <td>-0.005488742979949136</td>\n      <td>-0.005488742712222994</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table = np.array([[\"output bias\", b_o_diff, b_o_grad, b_o_est],\n",
    "                         [\"hidden bias\", b_h_diff, b_h_grad, b_h_est],\n",
    "                         [\"hidden-output weight_1\", w_ho_1_diff, w_ho_1_grad, w_ho_1_est],\n",
    "                         [\"hidden-output weight_2\", w_ho_2_diff, w_ho_2_grad, w_ho_2_est],\n",
    "                         [\"input-hidden weight_1\", w_ih_1_diff, w_ih_1_grad, w_ih_1_est],\n",
    "                         [\"input-hidden weight_2\", w_ih_2_diff, w_ih_2_grad, w_ih_2_est]\n",
    "                         ])\n",
    "\n",
    "pd.DataFrame(report_table, columns=[\"name of weight\", \"difference\", \"actual gradient\", \"estimated gradient\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}