{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import data\n",
    "import neuralnet\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(seed = 100) # fix random seed to make things reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (a) Loading Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "((60000, 784), (60000,))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = data.load_data()\n",
    "train_val[0].shape, train_val[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((10000, 784), (10000,))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.load_data(train=False)\n",
    "test[0].shape, test[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-process\n",
    "#### Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_x, train_y = train_val\n",
    "train_x, _ = data.z_score_normalize(train_x)\n",
    "train_val = train_x, train_y\n",
    "\n",
    "test_x, test_y = test\n",
    "test_x, _ = data.z_score_normalize(test_x)\n",
    "test_val = test_x, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (b) Check gradient implementation\n",
    "\n",
    "We only use a small subset of data to do this part. Thus, we use 1000 random data from the train/validation set.\n",
    "\n",
    "##### get a small subset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# shuffle dataset\n",
    "imgs, labs = train_val\n",
    "\n",
    "shuffled_idx = np.random.permutation(len(train_val[1]))\n",
    "\n",
    "imgs = imgs[shuffled_idx]\n",
    "labs =labs[shuffled_idx]\n",
    "\n",
    "# get a small subset\n",
    "small_set = imgs[: 1], labs[:1]\n",
    "print(small_set[0].shape)\n",
    "print(small_set[1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### get some functions to find weight and gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get a network first\n",
    "config = data.load_config((\"./config.yaml\"))\n",
    "nn = neuralnet.NeuralNetwork(config)\n",
    "\n",
    "small_x, small_y = small_set[0], small_set[1]\n",
    "\n",
    "# get a nn\n",
    "output = nn(small_x, targets=small_y)\n",
    "\n",
    "# get weights by backpropagation\n",
    "nn.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "epsilon = 0.01\n",
    "\n",
    "def get_weight_grad(name, layer, idx, nn, is_bias=False):\n",
    "    if is_bias:\n",
    "        weight = nn.layers[layer].b[0][idx]\n",
    "        grad = nn.layers[layer].d_b[idx]\n",
    "    else:\n",
    "        weight = nn.layers[layer].w[0][idx]\n",
    "        grad = nn.layers[layer].d_w[0][idx]\n",
    "\n",
    "    print(name, \":(\", \"weight:\", weight, \"gradient:\", grad, \")\")\n",
    "    return weight, grad\n",
    "\n",
    "def get_loss(weight, layer, idx, nn, is_bias=False):\n",
    "    higher = weight + epsilon\n",
    "    lower = weight - epsilon\n",
    "\n",
    "    if is_bias:\n",
    "        nn.layers[layer].b[0][idx] = higher\n",
    "        _, higher_loss = nn.forward(small_x, targets=small_y)\n",
    "        nn.layers[layer].b[0][idx] = lower\n",
    "        _, lower_loss = nn.forward(small_x, targets=small_y)\n",
    "\n",
    "        # reset nn\n",
    "        nn.layers[layer].b[0][idx] = weight\n",
    "    else:\n",
    "        nn.layers[layer].w[0][idx] = higher\n",
    "        _, higher_loss = nn.forward(small_x, targets=small_y)\n",
    "        nn.layers[layer].w[0][idx] = lower\n",
    "        _, lower_loss = nn.forward(small_x, targets=small_y)\n",
    "\n",
    "        # reset nn\n",
    "        nn.layers[layer].w[0][idx] = weight\n",
    "\n",
    "    print(\"Higher loss is:\", higher_loss)\n",
    "    print(\"Lower loss is:\", lower_loss)\n",
    "    return higher_loss, lower_loss\n",
    "\n",
    "def get_estimate(higher, lower):\n",
    "    est = (higher - lower) / (2 * epsilon)\n",
    "    print(\"estimated gradient is:\", est)\n",
    "    return est\n",
    "\n",
    "def diff_grad(grad, est):\n",
    "    diff = np.abs((grad - est))\n",
    "    print(\"difference between estimated and gradient is:\", diff)\n",
    "    return diff\n",
    "\n",
    "def check_grad(name, layer, idx, nn, is_bias=False):\n",
    "    weight, grad = get_weight_grad(name, layer, idx, nn, is_bias=is_bias)\n",
    "    higher, lower = get_loss(weight, layer, idx, nn, is_bias=is_bias)\n",
    "    est = get_estimate(higher, lower)\n",
    "    diff = diff_grad(grad, est)\n",
    "\n",
    "    return diff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### bias of output weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output bias :( weight: 0.0 gradient: 0.012671104872593866 )\n",
      "Higher loss is: 2.153077486743764\n",
      "Lower loss is: 2.152824060581794\n",
      "estimated gradient is: 0.0126713080984997\n",
      "difference between estimated and gradient is: 2.0322590583467248e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": "2.0322590583467248e-07"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias of output\n",
    "check_grad(\"output bias\", 2, 7, nn, is_bias=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### bias of hidden weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden bias :( weight: 0.0 gradient: -0.1182257632568207 )\n",
      "Higher loss is: 2.1517643388554943\n",
      "Lower loss is: 2.1541287967614338\n",
      "estimated gradient is: -0.11822289529697105\n",
      "difference between estimated and gradient is: 2.8679598496478276e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": "2.8679598496478276e-06"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_grad(\"hidden bias\", 0, 7, nn, is_bias=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### weight of hidden to output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden-output weight_1 :( weight: 0.0959293411441136 gradient: 0.009273564165974427 )\n",
      "Higher loss is: 2.153043219621119\n",
      "Lower loss is: 2.152857746744473\n",
      "estimated gradient is: 0.009273643832297118\n",
      "difference between estimated and gradient is: 7.966632269151841e-08\n",
      "hidden-output weight_2 :( weight: -0.058684298241869014 gradient: 0.009660359079762365 )\n",
      "Higher loss is: 2.153047101390139\n",
      "Lower loss is: 2.152853892551448\n",
      "estimated gradient is: 0.009660441934533637\n",
      "difference between estimated and gradient is: 8.285477127133178e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": "8.285477127133178e-08"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_grad(\"hidden-output weight_1\", 2, 7, nn, is_bias=False)\n",
    "check_grad(\"hidden-output weight_2\", 2, 8, nn, is_bias=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### weight of input to hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input-hidden weight_1 :( weight: 0.03876130722157737 gradient: 0.005871529380401278 )\n",
      "Higher loss is: 2.153008854589536\n",
      "Lower loss is: 2.152891424008954\n",
      "estimated gradient is: 0.00587152902908894\n",
      "difference between estimated and gradient is: 3.513123377277272e-10\n",
      "input-hidden weight_2 :( weight: -0.023712037277713923 gradient: -0.005488742979949136 )\n",
      "Higher loss is: 2.1528952505826426\n",
      "Lower loss is: 2.153005025436887\n",
      "estimated gradient is: -0.005488742712222994\n",
      "difference between estimated and gradient is: 2.677261424707811e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": "2.677261424707811e-10"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_grad(\"input-hidden weight_1\", 0, 7, nn, is_bias=False)\n",
    "check_grad(\"input-hidden weight_2\", 0, 8, nn, is_bias=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}